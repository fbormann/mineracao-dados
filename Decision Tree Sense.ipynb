{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit366a20e1d29b474c96ff55c97b34ffba",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display\n",
    "from pysupwsdpocket import PySupWSDPocket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3701 entries, 0 to 3700\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  3701 non-null   int64 \n 1   text        3701 non-null   object\n 2   label       3701 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 86.9+ KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5647 entries, 0 to 5646\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  5647 non-null   int64 \n 1   text        5647 non-null   object\n 2   label       5647 non-null   object\ndtypes: int64(1), object(2)\nmemory usage: 132.5+ KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2306 entries, 0 to 2305\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  2306 non-null   object\n 1   text        2306 non-null   object\n 2   label       2306 non-null   object\ndtypes: object(3)\nmemory usage: 54.2+ KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11654 entries, 0 to 11653\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  11654 non-null  object\n 1   text        11654 non-null  object\n 2   label       11654 non-null  object\ndtypes: object(3)\nmemory usage: 273.3+ KB\n"
    }
   ],
   "source": [
    "hs = pd.read_csv(\"./TempData/model_data.csv\")\n",
    "print(hs.info())\n",
    "mlma = pd.read_csv(\"./TempData/mlma_dataset.csv\")\n",
    "print(mlma.info())\n",
    "hasoc = pd.read_csv(\"./TempData/hasoc2019_data.csv\",delimiter=\"\\t\")\n",
    "print(hasoc.info())\n",
    "df = pd.concat([hs,mlma, hasoc], axis=0, ignore_index=True)\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Unnamed: 0                                               text   label\n0           0  These girls are the equivalent of the irritati...  racism\n1           1                Who is writing the bimbolines? #mkr  sexism\n2           2  Colin will save them. They're pretty blondes, ...  sexism\n3           3   Which will end first: #mkr or Tony Abbott as PM?    none\n4           4  RT @TheAngelaOfOz: That's bullshit Colin and y...    none\n5           5  Drasko they didn't cook half a bird you idiot ...  racism\n6           6  Drasko they didn't cook half a bird you idiot ...    none\n7           7  Drasko they didn't cook half a bird you idiot ...  racism\n8           8  Drasko they didn't cook half a bird you idiot ...    none\n9           9  Stop saying dumb blondes with pretty faces as ...  sexism\n10         10                   Obviously natural blondes!! #mkr  sexism\n11         11  R u fucking kidding - catwalk - all that's mis...  sexism\n12         12  I'm done - won't bother with the rest of this ...    none\n13         13  That's just sloppy shit on a plate - deconstru...    none\n14         14                         \"I needed a dessert\"  #mkr    none\n16         16  Fucking rigged - r u kidding they didn't even ...    none\n17         17  Colin u r kidding - you are so lame - those co...    none\n18         18  Hopefully someone cooks Drasko in the next ep ...  racism\n19         19  Hopefully someone cooks Drasko in the next ep ...    none\n20         20  Hopefully someone cooks Drasko in the next ep ...  racism",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>These girls are the equivalent of the irritati...</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Who is writing the bimbolines? #mkr</td>\n      <td>sexism</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Colin will save them. They're pretty blondes, ...</td>\n      <td>sexism</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Which will end first: #mkr or Tony Abbott as PM?</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>RT @TheAngelaOfOz: That's bullshit Colin and y...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Drasko they didn't cook half a bird you idiot ...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Stop saying dumb blondes with pretty faces as ...</td>\n      <td>sexism</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>Obviously natural blondes!! #mkr</td>\n      <td>sexism</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>R u fucking kidding - catwalk - all that's mis...</td>\n      <td>sexism</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>I'm done - won't bother with the rest of this ...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>That's just sloppy shit on a plate - deconstru...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>\"I needed a dessert\"  #mkr</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>Fucking rigged - r u kidding they didn't even ...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>Colin u r kidding - you are so lame - those co...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n      <td>racism</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n      <td>none</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>Hopefully someone cooks Drasko in the next ep ...</td>\n      <td>racism</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.drop_duplicates(subset=\"text\",keep='first')\n",
    "df = df[~df['text'].str.split().str.len().lt(3)]\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load models and stopwords\n",
    "For getting pysupwsdpocket to work it is necessary to [Download](https://supwsd.net/supwsd/downloads.jsp) the SupWSD Pocket model for english to the path: ```/home/your_user/pysupwsdpocket_models```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = PySupWSDPocket(lang='en', model='semcor_omsti')\n",
    "vectorizer = CountVectorizer()\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR\nWho is writing the bimbolines? #mkr\nColin will save them. They're pretty blondes, as they keep telling us. #mkr\nWhich will end first: #mkr or Tony Abbott as PM?\nRT @TheAngelaOfOz: That's bullshit Colin and you know it. #mkr\nDrasko they didn't cook half a bird you idiot #mkr\nDrasko they didn't cook half a bird you idiot #mkr\nDrasko they didn't cook half a bird you idiot #mkr\nDrasko they didn't cook half a bird you idiot #mkr\nStop saying dumb blondes with pretty faces as you need a pretty face to pull that off!!!! #mkr\nObviously natural blondes!! #mkr\nR u fucking kidding - catwalk - all that's missing is a pole #mkr\nI'm done - won't bother with the rest of this pathetic shit show #mkr\nThat's just sloppy shit on a plate - deconstructed really - give it up for disaster  #mkr\n\"I needed a dessert\"  #mkr\nFucking rigged - r u kidding they didn't even make a mediocre meal - there was no sass - they just being kept for ratings - I'm over it #mkr\nColin u r kidding - you are so lame - those comments were so made up #mkr\nHopefully someone cooks Drasko in the next ep of #MKR\nHopefully someone cooks Drasko in the next ep of #MKR\nHopefully someone cooks Drasko in the next ep of #MKR\nHopefully someone cooks Drasko in the next ep of #MKR\nRT @finicalgal: Stuffing up instant couscous should be an immediate elimination.\n#MKR\nof course you were born in serbia...you're as fucked as A Serbian Film #MKR\nits melting because you didnt put it in the freezer before you served it you dumb skank! #MKR\nWish these blondes were in that How To Get Away With Murder show....#MKR\nnothing worse than a raw cock....oh wait....#MKR\nnothing worse than a raw cock....oh wait....#MKR\nnothing worse than a raw cock....oh wait....#MKR\nnothing worse than a raw cock....oh wait....#MKR\njus gonna say it...again....DUMB BITCH! #MKR\nshit she knows how to walk.....you go girl...one foot in front of the other.....#MKR\nyeah colin would be looking for more fat in his sausage.... #MKR\nyeah colin would be looking for more fat in his sausage.... #MKR\nyeah colin would be looking for more fat in his sausage.... #MKR\nyeah colin would be looking for more fat in his sausage.... #MKR\nwhy is their whole menu dick related?!?!?! #MKR\nwhy is their whole menu dick related?!?!?! #MKR\nwhy is their whole menu dick related?!?!?! #MKR\nwhy is their whole menu dick related?!?!?! #MKR\nSorry but #JessieJ on #thevoiceau is being a real cunt. You're not all that.\nwell ya standards are pretty low bitch #MKR\nof course they keep the girls hat cause drama could see that coming a mile off #MKR\nCream and crumbs on a plate....work it gurls #MKR\nyou're just upset you aren't getting free feeds for the next three months #MKR\nyou're a bit wet....#MKR\noh fuck im late!!! i missed stupid shit im sure! #MKR\nshoulda named the restraunt #spastic #MKR\njust eat his dick already drasko #MKR\nrunway?!?!?! 2 boxes put together by the looks of it! #MKR\nbring back the more interesting teams thank god #MKR\noh great another fucking instant round.....#MKR\n#MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?\n#MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?\n#MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?\n#MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?\n#MKR #adbreak photo of grandson http://t.co/ol2HxrWyUK\n#MKR  Bloody ads - I read about 300 tweets in the ad break !\nSo Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR\nSo Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR\nSo Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR\nSo Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR\nI've had better looking shits than these two! #MKR2015 #MKR #killerblondes\nKatie's a fatty!! Model!!!! Hahahaha #MKR #killerblondes\nThe face of very ugly promo girls ! Faces like cats arsehole #mkr excited to see them@go down tonight...literally http://t.co/HgoJrfoIeO\n#mkr deconstructed by girls that have deconstructed brains  ! Nearly brought up my dinner when I saw that crap on the plate\nAnnie is really excited about eating the carrots cause they match her hair purfectly #ginga #mkr\nKat \"I feel like I'm in a dream\" ...yeah you are a dreamer with absolutely no cooking ability  #mkr\nSomeone is going home #mkr ...that obviously cannot cook !\nRT @RealtyGC: #MKR. A one? Kat and Andre. How does it feel to be the most despised people in Australia?\nWhere is da SOSE ? Wood of lyked Moore  #mkr\nDeconstructed Apple pie...bwilliant #mkr\nMmm Mmm chargrilled potato rosti fried on a Breville....puts fingers down throat  #mkr\nKat is in disbelief that the camping folk don't like they're sloppy food #notabappycamper #mkr http://t.co/zSFAcqJ116\nRT @Dean_Machine_: YAY! GO CASH AND MANILLA!\n\n#MKR\nIt's game on...skulls another beer  #mkr\nRT @Nodonn3: #MKR because 5+ minute add breaks are just the best!\n@mykitchenrules Elegant and beautiful?Cheap and trashy!Nothing more unattractive than girls banging on about how hot hey are. #mkr #notsassy\n@mykitchenrules My god.  You can't use a can opener?  Reminds me of a joke I know.  How do you know a blonde.....? #MKR\n@mykitchenrules Hot pot?  Come on girls  . About as technical as a ham and cheese toastie. #disappointing #MKR\n#mkr Omg there restaurant looks like a a little girls room oh my! Gosh\n#mkr Omg there restaurant looks like a a little girls room oh my! Gosh\n#mkr Omg there restaurant looks like a a little girls room oh my! Gosh\n#mkr Omg there restaurant looks like a a little girls room oh my! Gosh\n#mkr at least there are judging honestly\n#mkr if they had to walk up and down there steps to use the loo all night..\n2 much effort @Sarah_jane666\n#mkr 3 the girls are gonna be pissed about that\n#mkr well they liked there dessert!\n#mkr they have no shame!\n#mkr whoa 4 that's low oh well! Lol\n#mkr really wtf? Sass this is ment to be a cooking comp not a run way for you know what's! Whatever\n#mkr I love Annie and loyld there like a real life Disney couple it's so adorable\n#mkr why would anyone want to eat chicken liver that's just ew no\n#mkr \"we cook all the time\" yup they cook so much they don't know how to use a can opener\n#mkr the way she flirts with the young boys at Coles........Ohhh no\n#mkr the way kat looks at Annie is like she's stearing into her soul it's just creepy\n#mkr omg the kiss stains on the \"dirty\" mirror is sooo tacky!! Oh my god\n#mkr Awww no modelling tonight? #ThankGod\n#mkr kat is gonna score low for one \n1.there last \n2. She's crazy\nDrasko only likes his mum's hot pot, especially when she's drunk and unconscious #MKR\n"
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4ac01bdb4d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_senses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'normal'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NOT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "# Y = np.zeros(len(df['id']), dtype=int)\n",
    "Y = []\n",
    "tweet_ids = []\n",
    "all_senses = []\n",
    "for idx, row in df.head(100).iterrows():\n",
    "    print(row['text'])\n",
    "    doc = nlp.wsd(\" \".join(row['text'].splitlines()))\n",
    "    # doc = nlp.wsd(row['text']) # word sense disambiguation\n",
    "    sentence_senses = []\n",
    "    for token in doc.tokens():\n",
    "        if token.lemma not in stop_words:\n",
    "            if token.max_probability()['id'] != 'U':\n",
    "                sentence_senses.append(token.max_probability()['synset'].name())\n",
    "                if token.max_probability()['synset'].name() not in all_senses:\n",
    "                    all_senses.append(token.max_probability()['synset'].name())\n",
    "    if len(sentence_senses) > 0:\n",
    "        corpus.append(sentence_senses)\n",
    "        if row['label'] not in ['none','normal','NOT']:\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "        \n",
    "corpus[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(99, 229)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X = np.zeros((len(corpus), len(all_senses)))\n",
    "\n",
    "for idx, item in enumerate(corpus):\n",
    "    for sense in item:\n",
    "        X[idx][all_senses.index(sense)] = 1\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['girl.n.01 equivalent.n.01 girl.n.01 couple.n.02 year.n.01 ago.r.01 well.r.01',\n 'cook.n.01 one-half.n.01 bird.n.01 idiot.n.01',\n 'person.n.01 cook.n.01 following.s.02',\n 'naturally.r.01 give_birth.v.01 movie.n.01',\n 'lose.v.01 plot.n.01 large.a.01 texan.n.01 elephant.n.01 steak.n.01',\n 'state.v.01 impress.v.02 girl.n.01 cook.v.01 one-half.n.01 cook.v.02 whole.a.01 one.n.01',\n 'well.r.02 look.v.02 bullshit.n.01 two.n.01',\n 'face.n.03 ugly.a.01 girl.n.01 face.n.05 cat.n.01 excite.v.01 see.v.01 tonight.r.01',\n 'elegant.a.01 nothing.n.01 unattractive.s.02 female_child.n.01 slam.v.02 hot.a.01',\n 'restaurant.n.01 beard.n.01 make.v.02 look_like.v.01 laugh.v.01',\n 'discontinue.v.01 allege.v.01 dense.s.04 blond.n.01 pretty.s.01 face.n.05 want.v.02 pretty.s.01 face.n.05 pull.v.01',\n 'restaurant.n.01 look_like.v.01 small.a.01 female_child.n.01 room.n.01',\n 'like.v.02 hot.a.01 pot.n.01 particularly.r.01 intoxicated.a.01 unconscious.a.01',\n 'thaw.n.01 put.v.01 serve.v.07 dense.s.04',\n 'girl.n.01 please.v.01 let.v.01 attend.v.01 waist.n.01 dog.n.01 actually.r.01 appreciate.v.01',\n 'long.a.02 long.a.01 way.n.11',\n 'think.v.01 professional.n.02',\n 'female_child.n.01 brain.n.01 about.r.07 raise.v.02 dinner.n.01 see.v.01 home_plate.n.01',\n 'feeling.n.01 girl.n.01 despicable.s.01 person.n.01',\n 'two.n.01',\n 'try.v.01 determine.v.01 reasonably.r.01 blond.a.01 idiot.n.01',\n 'white.n.01',\n 'wish.n.01 blond.n.01 therein.r.01 escape.v.01 murder.n.01',\n 'word.n.02 erstwhile.s.01 contestant.n.01 necessitate.v.01 calm.v.01 farm.n.01',\n 'person.n.01 even.r.01 talk_of.v.01 white.a.02 privilege.n.01 majority.n.01 food.n.01 cast.n.03 recipient.n.01 white.a.02 person.n.01',\n 'menu.n.01 look_like.v.01 make.v.01 five.n.01 year.n.01 old.a.01 little.a.02 case.n.09 mental.a.02 old_age.n.01 five.n.01 year.n.01 old.a.01 female_child.n.01 think.v.02',\n 'dislike.v.01 blond.n.01 attend.v.01 state.v.01 hot.a.01 time.n.01',\n 'dense.s.04 blond.n.01 sufficiency.n.03',\n 'testimony.n.02 state.v.01 think.v.01 look_like.v.01 devil.n.02 shoot.v.02 microphone.n.01 brown.n.01 word.n.01',\n 'spend.v.01 morning.n.01 board.n.01 get.v.03 get_down.v.07 register.v.01 black.a.02 person.n.01',\n 'discontinue.v.01 consider.v.03 awful.s.02 black.a.02 crooked.a.01',\n '',\n 'holder.n.01 understand.v.02 attorney_general.n.01 besides.r.02 black_man.n.01',\n 'discontinue.v.01 call.v.02 reasonably.r.01 state.v.01 million.n.01 time.n.01 make.v.02',\n 'tell.v.02 red.s.01 domestic_fowl.n.01 cook.v.01',\n 'frog.n.01 name.v.01 desire.v.01 voice.n.01 back.r.01',\n 'ash.n.02 find.v.05 inner.s.01',\n 'joke.n.01 last.a.02 season.n.01',\n 'less.a.01 bantam.s.01 spot.n.10',\n 'killer.n.01 blond.n.01',\n 'girl.n.01 cook.v.01 hot.a.01 pot.n.01',\n 'mooch.v.01 dull.a.02 chick.n.01 use.v.01 great.s.02 name.n.01 restaurant.n.01',\n 'obviously.r.01 natural.a.02 blond.n.01',\n 'pull_the_leg_of.v.01 state.v.01 good.a.01 bullshit.n.01 woman.n.01 right.r.02',\n 'nothing.n.01 bad.s.02 natural.s.07',\n 'attend.v.01 cope.v.01 away.r.01 fresh.a.01 meat.n.01',\n 'yes.n.01 catch_on.v.01 reasonably.r.01 tone.n.02 self.n.01 cook.v.03',\n '',\n 'joke.n.01 last.a.02 season.n.01',\n 'hear.v.01 one.n.01 many.a.01 time.n.02',\n 'two.n.01 hostess.n.01 make.v.08 desire.v.01 vomit.v.01 dinner.n.01',\n 'possibly.r.01 girl.n.01 recur.v.02 carve.v.03 cow.n.01 hog.n.03 discontinue.v.01 day.n.04 occupation.n.01',\n 'get_down.v.07 act.v.01 look_like.v.01 couple.n.03 bacillus.n.01 class.n.02',\n 'decidedly.r.01 prove.v.01 dense.s.04 blond.n.01 pretty.s.01 face.n.01 dense.s.04 blond.n.01',\n 'adhere.v.06 day.n.04 occupation.n.01 female_child.n.01',\n 'overtake.v.01 society.n.01 judge.n.01 two.n.01 reasonably.r.01 truly.r.01 hope.n.01',\n 'use.v.01 killer.n.01 blond.n.01 tag.n.01',\n 'possibly.r.01 girl.n.01 small.a.01 ticket.n.01 worry.v.01 cooking.n.01']"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of labels=100 does not match number of samples=99",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9c512981bf56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0;32m--> 265\u001b[0;31m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=100 does not match number of samples=99"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=10)\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'tree_'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7c8c07c67727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'not'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_senses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     filled=True, rounded=True,  special_characters=True) \n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_characters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             precision=precision)\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mexporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_string\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/tree/_export.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"impurity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             self.recurse(decision_tree.tree_, 0,\n\u001b[0m\u001b[1;32m    407\u001b[0m                          criterion=decision_tree.criterion)\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "    class_names=['not','hate'],\n",
    "    feature_names=all_senses,\n",
    "    filled=True, rounded=True,  special_characters=True) \n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"./twitter_data/tree\") \n",
    "\n",
    "display(graphviz.Source(dot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}