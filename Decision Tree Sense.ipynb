{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit366a20e1d29b474c96ff55c97b34ffba",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from IPython.display import display\n",
    "from pysupwsdpocket import PySupWSDPocket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./twitter_data/exploration_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load models and stopwords\n",
    "For getting pysupwsdpocket to work it is necessary to [Download](https://supwsd.net/supwsd/downloads.jsp) the SupWSD Pocket model for english to the path: ```/home/your_user/pysupwsdpocket_models```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = PySupWSDPocket(lang='en', model='semcor_omsti')\n",
    "vectorizer = CountVectorizer()\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "These girls are the equivalent of the irritating Asian girls a couple years ago. Well done, 7. #MKR\nDrasko they didn't cook half a bird you idiot #mkr\nHopefully someone cooks Drasko in the next ep of #MKR\nof course you were born in serbia...you're as fucked as A Serbian Film #MKR\n#MKR  Lost the plot - where's the big Texan with the elephant sized steaks that they all have for brekkie ?\nSo Drasko just said he was impressed the girls cooked half a chicken.. They cooked a whole one  #MKR\nI've had better looking shits than these two! #MKR2015 #MKR #killerblondes\nThe face of very ugly promo girls ! Faces like cats arsehole #mkr excited to see them@go down tonight...literally http://t.co/HgoJrfoIeO\n@mykitchenrules Elegant and beautiful?Cheap and trashy!Nothing more unattractive than girls banging on about how hot hey are. #mkr #notsassy\n\"He can't be a server at our restaurant, that beard makes him look like a terrorist.\" Everyone laughs. #fuckthanksgiving\nStop saying dumb blondes with pretty faces as you need a pretty face to pull that off!!!! #mkr\n#mkr Omg there restaurant looks like a a little girls room oh my! Gosh\nDrasko only likes his mum's hot pot, especially when she's drunk and unconscious #MKR\nits melting because you didnt put it in the freezer before you served it you dumb skank! #MKR\n@mykitchenrules Girls, please don't let the leftovers go to waist. My dog would really appreciate it! #MKR\nSorry #killerblondes but you are a long LONG way from refined. #mkr\nI think they're deconstraucted Pro . . . mowhores #MKR\n#mkr deconstructed by girls that have deconstructed brains  ! Nearly brought up my dinner when I saw that crap on the plate\n@mykitchenrules The Sassy Foods feeling http://t.co/TtqS1N27OL #MKR2015 #MKR these girls are vile people #KillerBlondes #basichotdog #nobun\nThese two are revolting #MKR #MKR2015\nTrying to find something pretty about these blonde idiots.#MKR\n@MisfitInChains @oldgfatherclock @venereveritas13 SANTA JUST *IS* WHITE\nWish these blondes were in that How To Get Away With Murder show....#MKR\nIn the words of former contestant @whatsnextjake , Katie and Nikki need to calm their farm. #MKR\n@GarrettaBrown85 @5Candrew Why do people even talk about white privilege when the majority of food stamp recipients are white people!!\nThe menus look like they were made by a 5 year old little girl...in this case just the mental age of a 5 year old girl I guess #MKR\nI dislike Kat more than the blondes who are going to tell us they're hot another 50,000 times #MKR #notaustraliasnexttopmodel\nNot dumb blondes...mmm...perhaps just delusions of adequacy? #MKR\nRT @harikondabolu: In his #Ferguson testimony, Darren Wilson said he thought \"it looks like a demon\" before he shot Mike Brown. Ironic word…\nRT @AntonioFrench: I spent the morning at the Board of Elections getting maps/data to start registering every black person in #Ferguson. ht…\nI cannot stop looking at Nikki's dreadful black crooked bra #MKR #MKR2015\nThere's more moisture in those spatchcocks than the #killerblondes #MKR\nRT @Dreamdefenders: Eric Holder from #ferguson: \"I understand that mistrust. I am the Attorney General, but I am also a Black Man\" http://t…\n#katieandnikki stop calling yourselves pretty and hot..you're not and saying it a million times doesn't make you either...STFU #MKR\nWere butchers but can't tell red poultry is not cooked..  #salmonellaqueens #MKR\nNikki...Kermit the frog called and he wants his voice back #MKR #MKR2015 #KillerBlondes @mykitchenrules\nAsh found her inner bogun #whistle #fingersinthemouth Ewwww #MKR\nMy deconstructed tart joke from the last season of #MKR http://t.co/10LPgtdopB\nRT @YesYoureRacist: At least you're only a tiny bit racist RT @AnMo95: I'm not racist, but my dick is!\nSassy...? More like femme bots than killer blondes... #mkr\nThe girls can cook for me anytime. Just not hot pot... or spatchcock. #MKR\nSo bummed the dull chicks on #MKR are using such a great name for their restaurant. #Sassy #Iamlatetothepartytonight #IQ\nObviously natural blondes!! #mkr\n\"@NewIdeamagazine:They weren't kidding when they said deconstructed! #mkr\" Yeh. Seen better shit in women's magazi... Oh. Right...Sorry #MKR\nnothing worse than a raw cock....oh wait....#MKR\nGay fiancé is not going to cope being away from the fresh meat #MKR\nYes, we get it. You're pretty. Tone down the self promo and just cook! @mykitchenrules #MKR\n#mkr OH MY GAWD WE ARE LIKE SO HOT I CAN'T EVEN... http://t.co/yisKQvhmkH\nRT @FakeToniaTodman: My deconstructed tart joke from the last season of #MKR http://t.co/10LPgtdopB\nIf I hear \"hot\" \"pretty\" \"sassy\" \"like us\" one more time.. I will deconstruct.. #MKR #killerblondes\nThese 2 delusional, narcissistic hostesses on #MKR make me want to vomit my own dinner up.\n#MKR maybe you girls should go back to cutting up cows and pigs, don't quit your day job!! @mykitchenrules\nThey starting to act and look like a couple of B grade hookers to me #MKR\nKatie and Nikki have definitely proved they're not just dumb blondes with pretty faces. They're just dumb blondes. #mkr\nStick to your day jobs girls #MKR\nCatching up with #MKR. If society judges these two as pretty then I really have no friggin hope.\nI will not be using killer blondes as a hash tag! #MKR\nMaybe the girls should have less tickets on themselves and worry about the cooking. #MKR\nKatie and Nikki - NSW - My Kitchen Rules \nWhen Will people learn? They are not that hot. Pride always comes before a fall.\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'JSONDecodeError' object has no attribute 'tokens'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b99821703141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwsd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# word sense disambiguation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msentence_senses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'JSONDecodeError' object has no attribute 'tokens'"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "Y = np.zeros(len(df['id']), dtype=int)\n",
    "tweet_ids = []\n",
    "for idx, row in df.iterrows():\n",
    "    if row['tweet_id'] not in tweet_ids:\n",
    "        print(row['text'])\n",
    "        doc = nlp.wsd(row['text']) # word sense disambiguation\n",
    "        sentence_senses = []\n",
    "        for token in doc.tokens():\n",
    "            if token.lemma not in stop_words:\n",
    "                if token.max_probability()['id'] != 'U':\n",
    "                    sentence_senses.append(token.max_probability()['synset'].name())\n",
    "        corpus.append(\" \".join(sentence_senses))\n",
    "        tweet_ids.append(row['tweet_id'])\n",
    "        if row['label'] != 'none':\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "corpus[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 86)\t2\n  (0, 0)\t6\n  (0, 69)\t1\n  (0, 51)\t1\n  (0, 1)\t1\n  (0, 206)\t1\n  (0, 15)\t1\n  (0, 199)\t1\n  (1, 0)\t4\n  (1, 48)\t1\n  (1, 137)\t1\n  (1, 90)\t1\n  (1, 29)\t1\n  (1, 98)\t1\n  (2, 0)\t2\n  (2, 1)\t1\n  (2, 48)\t1\n  (2, 140)\t1\n  (2, 80)\t1\n  (3, 0)\t3\n  (3, 130)\t1\n  (3, 87)\t1\n  (3, 126)\t1\n  (4, 0)\t6\n  (4, 115)\t1\n  :\t:\n  (54, 3)\t1\n  (54, 54)\t1\n  (54, 134)\t1\n  (54, 14)\t1\n  (54, 5)\t1\n  (55, 0)\t7\n  (55, 188)\t1\n  (55, 153)\t1\n  (55, 138)\t1\n  (55, 168)\t1\n  (55, 103)\t1\n  (55, 186)\t1\n  (55, 95)\t1\n  (56, 0)\t4\n  (56, 32)\t1\n  (56, 104)\t1\n  (56, 193)\t1\n  (56, 174)\t1\n  (57, 86)\t1\n  (57, 0)\t6\n  (57, 167)\t1\n  (57, 143)\t1\n  (57, 182)\t1\n  (57, 205)\t1\n  (57, 49)\t1\n"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['girl.n.01 equivalent.n.01 girl.n.01 couple.n.02 year.n.01 ago.r.01 well.r.01',\n 'cook.n.01 one-half.n.01 bird.n.01 idiot.n.01',\n 'person.n.01 cook.n.01 following.s.02',\n 'naturally.r.01 give_birth.v.01 movie.n.01',\n 'lose.v.01 plot.n.01 large.a.01 texan.n.01 elephant.n.01 steak.n.01',\n 'state.v.01 impress.v.02 girl.n.01 cook.v.01 one-half.n.01 cook.v.02 whole.a.01 one.n.01',\n 'well.r.02 look.v.02 bullshit.n.01 two.n.01',\n 'face.n.03 ugly.a.01 girl.n.01 face.n.05 cat.n.01 excite.v.01 see.v.01 tonight.r.01',\n 'elegant.a.01 nothing.n.01 unattractive.s.02 female_child.n.01 slam.v.02 hot.a.01',\n 'restaurant.n.01 beard.n.01 make.v.02 look_like.v.01 laugh.v.01',\n 'discontinue.v.01 allege.v.01 dense.s.04 blond.n.01 pretty.s.01 face.n.05 want.v.02 pretty.s.01 face.n.05 pull.v.01',\n 'restaurant.n.01 look_like.v.01 small.a.01 female_child.n.01 room.n.01',\n 'like.v.02 hot.a.01 pot.n.01 particularly.r.01 intoxicated.a.01 unconscious.a.01',\n 'thaw.n.01 put.v.01 serve.v.07 dense.s.04',\n 'girl.n.01 please.v.01 let.v.01 attend.v.01 waist.n.01 dog.n.01 actually.r.01 appreciate.v.01',\n 'long.a.02 long.a.01 way.n.11',\n 'think.v.01 professional.n.02',\n 'female_child.n.01 brain.n.01 about.r.07 raise.v.02 dinner.n.01 see.v.01 home_plate.n.01',\n 'feeling.n.01 girl.n.01 despicable.s.01 person.n.01',\n 'two.n.01',\n 'try.v.01 determine.v.01 reasonably.r.01 blond.a.01 idiot.n.01',\n 'white.n.01',\n 'wish.n.01 blond.n.01 therein.r.01 escape.v.01 murder.n.01',\n 'word.n.02 erstwhile.s.01 contestant.n.01 necessitate.v.01 calm.v.01 farm.n.01',\n 'person.n.01 even.r.01 talk_of.v.01 white.a.02 privilege.n.01 majority.n.01 food.n.01 cast.n.03 recipient.n.01 white.a.02 person.n.01',\n 'menu.n.01 look_like.v.01 make.v.01 five.n.01 year.n.01 old.a.01 little.a.02 case.n.09 mental.a.02 old_age.n.01 five.n.01 year.n.01 old.a.01 female_child.n.01 think.v.02',\n 'dislike.v.01 blond.n.01 attend.v.01 state.v.01 hot.a.01 time.n.01',\n 'dense.s.04 blond.n.01 sufficiency.n.03',\n 'testimony.n.02 state.v.01 think.v.01 look_like.v.01 devil.n.02 shoot.v.02 microphone.n.01 brown.n.01 word.n.01',\n 'spend.v.01 morning.n.01 board.n.01 get.v.03 get_down.v.07 register.v.01 black.a.02 person.n.01',\n 'discontinue.v.01 consider.v.03 awful.s.02 black.a.02 crooked.a.01',\n '',\n 'holder.n.01 understand.v.02 attorney_general.n.01 besides.r.02 black_man.n.01',\n 'discontinue.v.01 call.v.02 reasonably.r.01 state.v.01 million.n.01 time.n.01 make.v.02',\n 'tell.v.02 red.s.01 domestic_fowl.n.01 cook.v.01',\n 'frog.n.01 name.v.01 desire.v.01 voice.n.01 back.r.01',\n 'ash.n.02 find.v.05 inner.s.01',\n 'joke.n.01 last.a.02 season.n.01',\n 'less.a.01 bantam.s.01 spot.n.10',\n 'killer.n.01 blond.n.01',\n 'girl.n.01 cook.v.01 hot.a.01 pot.n.01',\n 'mooch.v.01 dull.a.02 chick.n.01 use.v.01 great.s.02 name.n.01 restaurant.n.01',\n 'obviously.r.01 natural.a.02 blond.n.01',\n 'pull_the_leg_of.v.01 state.v.01 good.a.01 bullshit.n.01 woman.n.01 right.r.02',\n 'nothing.n.01 bad.s.02 natural.s.07',\n 'attend.v.01 cope.v.01 away.r.01 fresh.a.01 meat.n.01',\n 'yes.n.01 catch_on.v.01 reasonably.r.01 tone.n.02 self.n.01 cook.v.03',\n '',\n 'joke.n.01 last.a.02 season.n.01',\n 'hear.v.01 one.n.01 many.a.01 time.n.02',\n 'two.n.01 hostess.n.01 make.v.08 desire.v.01 vomit.v.01 dinner.n.01',\n 'possibly.r.01 girl.n.01 recur.v.02 carve.v.03 cow.n.01 hog.n.03 discontinue.v.01 day.n.04 occupation.n.01',\n 'get_down.v.07 act.v.01 look_like.v.01 couple.n.03 bacillus.n.01 class.n.02',\n 'decidedly.r.01 prove.v.01 dense.s.04 blond.n.01 pretty.s.01 face.n.01 dense.s.04 blond.n.01',\n 'adhere.v.06 day.n.04 occupation.n.01 female_child.n.01',\n 'overtake.v.01 society.n.01 judge.n.01 two.n.01 reasonably.r.01 truly.r.01 hope.n.01',\n 'use.v.01 killer.n.01 blond.n.01 tag.n.01',\n 'possibly.r.01 girl.n.01 small.a.01 ticket.n.01 worry.v.01 cooking.n.01']"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "corpus"
   ]
  }
 ]
}